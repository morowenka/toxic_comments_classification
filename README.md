# toxic_comments_classification


# NOTE: В ноутбуке содержатся нецензурные и оскорбительные слова. Такова была специфика задачи, я не хотел ни коим образом никого оскорбить. Все слова и выражения были использованы исключительно в целях исследования.

# Задача
Бинарная классификация комментариев на русском языке.

Классы: 'токсичные', 'нетоксичные'.

# Данные 
Данные взяты с портала kaggle, способ их загрузки имеется в ноутбуке, никаких внешних данных, кроме токена kaggle (как его получить я также описал в ноутбуке), не понадобится. [Ссылка на датасет](https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments).

# Модели
Модели библиотеки scikit-learn: 
- Logistic Regression
- SVM
- SGDClassifier
- Naive Bayes
- Random Forest

Также были использованы 2 предобученные модели с портала Hugging Face:
- SISmetanin
- Skolkovo

***Подробные результаты вы можете посмотреть в последнем разделе моего ноутбука.***
